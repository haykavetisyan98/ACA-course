{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a classification model for Survival.csv dataset\n",
    "Find dataset describtion here\n",
    "https://physionet.org/content/challenge-2012/1.0.0/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.metrics import classification_report, matthews_corrcoef, roc_auc_score, f1_score, precision_score, recall_score, precision_recall_curve, auc, roc_curve,average_precision_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestClassifier, AdaBoostRegressor, StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordid</th>\n",
       "      <th>SAPS-I</th>\n",
       "      <th>SOFA</th>\n",
       "      <th>Length_of_stay</th>\n",
       "      <th>Survival</th>\n",
       "      <th>In-hospital_death</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>...</th>\n",
       "      <th>SysABP_last</th>\n",
       "      <th>TroponinI_last</th>\n",
       "      <th>TroponinT_last</th>\n",
       "      <th>WBC_last</th>\n",
       "      <th>Weight_last</th>\n",
       "      <th>pH_last</th>\n",
       "      <th>MechVentStartTime</th>\n",
       "      <th>MechVentDuration</th>\n",
       "      <th>MechVentLast8Hour</th>\n",
       "      <th>UrineOutputSum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132539</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132540</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175.3</td>\n",
       "      <td>76.0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.3</td>\n",
       "      <td>81.6</td>\n",
       "      <td>7.37</td>\n",
       "      <td>71.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132541</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.7</td>\n",
       "      <td>...</td>\n",
       "      <td>126.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.2</td>\n",
       "      <td>56.7</td>\n",
       "      <td>7.47</td>\n",
       "      <td>617.0</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132543</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>575</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180.3</td>\n",
       "      <td>84.6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.9</td>\n",
       "      <td>84.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132545</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>918</td>\n",
       "      <td>0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   recordid  SAPS-I  SOFA  Length_of_stay  Survival  In-hospital_death   Age  \\\n",
       "0    132539       6     1               5        -1                  0  54.0   \n",
       "1    132540      16     8               8        -1                  0  76.0   \n",
       "2    132541      21    11              19        -1                  0  44.0   \n",
       "3    132543       7     1               9       575                  0  68.0   \n",
       "4    132545      17     2               4       918                  0  88.0   \n",
       "\n",
       "   Gender  Height  Weight  ...  SysABP_last  TroponinI_last  TroponinT_last  \\\n",
       "0     0.0     NaN     NaN  ...          NaN             NaN             NaN   \n",
       "1     1.0   175.3    76.0  ...        103.0             NaN             NaN   \n",
       "2     0.0     NaN    56.7  ...        126.0             NaN             NaN   \n",
       "3     1.0   180.3    84.6  ...          NaN             NaN             NaN   \n",
       "4     0.0     NaN     NaN  ...          NaN             NaN             NaN   \n",
       "\n",
       "   WBC_last  Weight_last  pH_last  MechVentStartTime  MechVentDuration  \\\n",
       "0       9.4          NaN      NaN                NaN               NaN   \n",
       "1      13.3         81.6     7.37               71.0             360.0   \n",
       "2       6.2         56.7     7.47              617.0            2160.0   \n",
       "3       7.9         84.6      NaN                NaN               NaN   \n",
       "4       4.8          NaN      NaN                NaN               NaN   \n",
       "\n",
       "   MechVentLast8Hour  UrineOutputSum  \n",
       "0                NaN             NaN  \n",
       "1                0.0             5.0  \n",
       "2                1.0            14.0  \n",
       "3                NaN             NaN  \n",
       "4                NaN             NaN  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Survival_dataset.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 117 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   SAPS-I             4000 non-null   int64  \n",
      " 1   SOFA               4000 non-null   int64  \n",
      " 2   In-hospital_death  4000 non-null   int64  \n",
      " 3   Age                4000 non-null   float64\n",
      " 4   Gender             3997 non-null   float64\n",
      " 5   Height             2106 non-null   float64\n",
      " 6   Weight             3669 non-null   float64\n",
      " 7   CCU                4000 non-null   int64  \n",
      " 8   CSRU               4000 non-null   int64  \n",
      " 9   SICU               4000 non-null   int64  \n",
      " 10  DiasABP_first      2779 non-null   float64\n",
      " 11  GCS_first          3936 non-null   float64\n",
      " 12  Glucose_first      3887 non-null   float64\n",
      " 13  HR_first           3937 non-null   float64\n",
      " 14  MAP_first          2792 non-null   float64\n",
      " 15  NIDiasABP_first    3482 non-null   float64\n",
      " 16  NIMAP_first        3480 non-null   float64\n",
      " 17  NISysABP_first     3485 non-null   float64\n",
      " 18  RespRate_first     1101 non-null   float64\n",
      " 19  SaO2_first         1792 non-null   float64\n",
      " 20  Temp_first         3936 non-null   float64\n",
      " 21  DiasABP_last       2779 non-null   float64\n",
      " 22  GCS_last           3936 non-null   float64\n",
      " 23  Glucose_last       3887 non-null   float64\n",
      " 24  HR_last            3937 non-null   float64\n",
      " 25  MAP_last           2792 non-null   float64\n",
      " 26  NIDiasABP_last     3482 non-null   float64\n",
      " 27  NIMAP_last         3480 non-null   float64\n",
      " 28  NISysABP_last      3485 non-null   float64\n",
      " 29  RespRate_last      1101 non-null   float64\n",
      " 30  SaO2_last          1792 non-null   float64\n",
      " 31  Temp_last          3936 non-null   float64\n",
      " 32  DiasABP_lowest     2779 non-null   float64\n",
      " 33  GCS_lowest         3936 non-null   float64\n",
      " 34  Glucose_lowest     3887 non-null   float64\n",
      " 35  HR_lowest          3937 non-null   float64\n",
      " 36  MAP_lowest         2792 non-null   float64\n",
      " 37  NIDiasABP_lowest   3482 non-null   float64\n",
      " 38  NIMAP_lowest       3480 non-null   float64\n",
      " 39  NISysABP_lowest    3485 non-null   float64\n",
      " 40  RespRate_lowest    1101 non-null   float64\n",
      " 41  SaO2_lowest        1792 non-null   float64\n",
      " 42  Temp_lowest        3936 non-null   float64\n",
      " 43  DiasABP_highest    2779 non-null   float64\n",
      " 44  GCS_highest        3936 non-null   float64\n",
      " 45  Glucose_highest    3887 non-null   float64\n",
      " 46  HR_highest         3937 non-null   float64\n",
      " 47  MAP_highest        2792 non-null   float64\n",
      " 48  NIDiasABP_highest  3482 non-null   float64\n",
      " 49  NIMAP_highest      3480 non-null   float64\n",
      " 50  NISysABP_highest   3485 non-null   float64\n",
      " 51  RespRate_highest   1101 non-null   float64\n",
      " 52  SaO2_highest       1792 non-null   float64\n",
      " 53  Temp_highest       3936 non-null   float64\n",
      " 54  DiasABP_median     2779 non-null   float64\n",
      " 55  GCS_median         3936 non-null   float64\n",
      " 56  Glucose_median     3887 non-null   float64\n",
      " 57  HR_median          3937 non-null   float64\n",
      " 58  MAP_median         2792 non-null   float64\n",
      " 59  NIDiasABP_median   3482 non-null   float64\n",
      " 60  NIMAP_median       3480 non-null   float64\n",
      " 61  NISysABP_median    3485 non-null   float64\n",
      " 62  RespRate_median    1101 non-null   float64\n",
      " 63  SaO2_median        1792 non-null   float64\n",
      " 64  Temp_median        3936 non-null   float64\n",
      " 65  ALP_first          1690 non-null   float64\n",
      " 66  ALT_first          1721 non-null   float64\n",
      " 67  AST_first          1725 non-null   float64\n",
      " 68  Albumin_first      1615 non-null   float64\n",
      " 69  BUN_first          3936 non-null   float64\n",
      " 70  Bilirubin_first    1718 non-null   float64\n",
      " 71  Cholesterol_first  305 non-null    float64\n",
      " 72  Creatinine_first   3936 non-null   float64\n",
      " 73  FiO2_first         2717 non-null   float64\n",
      " 74  HCO3_first         3924 non-null   float64\n",
      " 75  HCT_first          3936 non-null   float64\n",
      " 76  K_first            3904 non-null   float64\n",
      " 77  Lactate_first      2183 non-null   float64\n",
      " 78  Mg_first           3897 non-null   float64\n",
      " 79  Na_first           3925 non-null   float64\n",
      " 80  PaCO2_first        3023 non-null   float64\n",
      " 81  PaO2_first         3023 non-null   float64\n",
      " 82  Platelets_first    3932 non-null   float64\n",
      " 83  SysABP_first       2780 non-null   float64\n",
      " 84  TroponinI_first    205 non-null    float64\n",
      " 85  TroponinT_first    863 non-null    float64\n",
      " 86  WBC_first          3908 non-null   float64\n",
      " 87  Weight_first       2718 non-null   float64\n",
      " 88  pH_first           3038 non-null   float64\n",
      " 89  ALP_last           1690 non-null   float64\n",
      " 90  ALT_last           1721 non-null   float64\n",
      " 91  AST_last           1725 non-null   float64\n",
      " 92  Albumin_last       1615 non-null   float64\n",
      " 93  BUN_last           3936 non-null   float64\n",
      " 94  Bilirubin_last     1718 non-null   float64\n",
      " 95  Cholesterol_last   305 non-null    float64\n",
      " 96  Creatinine_last    3936 non-null   float64\n",
      " 97  FiO2_last          2717 non-null   float64\n",
      " 98  HCO3_last          3924 non-null   float64\n",
      " 99  HCT_last           3936 non-null   float64\n",
      " 100 K_last             3904 non-null   float64\n",
      " 101 Lactate_last       2183 non-null   float64\n",
      " 102 Mg_last            3897 non-null   float64\n",
      " 103 Na_last            3925 non-null   float64\n",
      " 104 PaCO2_last         3023 non-null   float64\n",
      " 105 PaO2_last          3023 non-null   float64\n",
      " 106 Platelets_last     3932 non-null   float64\n",
      " 107 SysABP_last        2780 non-null   float64\n",
      " 108 TroponinI_last     205 non-null    float64\n",
      " 109 TroponinT_last     863 non-null    float64\n",
      " 110 WBC_last           3908 non-null   float64\n",
      " 111 Weight_last        2718 non-null   float64\n",
      " 112 pH_last            3038 non-null   float64\n",
      " 113 MechVentStartTime  2529 non-null   float64\n",
      " 114 MechVentDuration   2529 non-null   float64\n",
      " 115 MechVentLast8Hour  2529 non-null   float64\n",
      " 116 UrineOutputSum     2529 non-null   float64\n",
      "dtypes: float64(111), int64(6)\n",
      "memory usage: 3.6 MB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['Length_of_stay', 'Survival','recordid'])\n",
    "df.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(thresh=3000, axis=1)\n",
    "df_final = df.fillna(df.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.rename(columns={'In-hospital_death': 'InHospitalDeath'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final.drop([\"InHospitalDeath\"], axis = 1).to_numpy()\n",
    "y = df_final.InHospitalDeath.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=24,  test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.319319520174482\n",
      "Best parameter: {'C': 200.0}\n"
     ]
    }
   ],
   "source": [
    "clf_svc_poly = SVC(kernel = \"poly\", random_state = 24)\n",
    "\n",
    "params = {\n",
    "    \"C\": np.linspace(50, 250, 5),\n",
    "}\n",
    "\n",
    "clf_svc_poly_cv = GridSearchCV(clf_svc_poly, params, cv = 3, scoring = \"f1\")\n",
    "clf_svc_poly_cv.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best score:\", clf_svc_poly_cv.best_score_)\n",
    "print(\"Best parameter:\", clf_svc_poly_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       698\n",
      "           1       0.41      0.27      0.33       102\n",
      "\n",
      "    accuracy                           0.86       800\n",
      "   macro avg       0.66      0.61      0.62       800\n",
      "weighted avg       0.84      0.86      0.84       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_svc_poly = SVC(kernel = \"poly\", random_state = 3, C=200)\n",
    "clf_svc_poly.fit(X_train, y_train)\n",
    "y_pred = clf_svc_poly.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       698\n",
      "           1       0.47      0.20      0.28       102\n",
      "\n",
      "    accuracy                           0.87       800\n",
      "   macro avg       0.68      0.58      0.60       800\n",
      "weighted avg       0.84      0.87      0.84       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_log = LogisticRegression(random_state=24).fit(X_train, y_train)\n",
    "y_pred = clf_log.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.29869115690986536\n",
      "Best parameter: {'max_depth': 7, 'max_leaf_nodes': 14}\n"
     ]
    }
   ],
   "source": [
    "clf_tree = DecisionTreeClassifier(random_state=24)\n",
    "\n",
    "params = {\n",
    "    \"max_depth\": np.arange(1, 20),\n",
    "    \"max_leaf_nodes\": np.arange(1, 20)\n",
    "}\n",
    "\n",
    "clf_cv = GridSearchCV(clf_tree, params, cv = 5, scoring = \"f1\")\n",
    "clf_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best score:\", clf_cv.best_score_)\n",
    "print(\"Best parameter:\", clf_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93       698\n",
      "           1       0.53      0.25      0.34       102\n",
      "\n",
      "    accuracy                           0.88       800\n",
      "   macro avg       0.71      0.61      0.64       800\n",
      "weighted avg       0.85      0.88      0.86       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_tree = DecisionTreeClassifier(max_depth=7, max_leaf_nodes=14,random_state=24)\n",
    "clf_tree.fit(X_train, y_train)\n",
    "y_pred = clf_tree.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA and LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90       698\n",
      "           1       0.37      0.45      0.41       102\n",
      "\n",
      "    accuracy                           0.83       800\n",
      "   macro avg       0.65      0.67      0.66       800\n",
      "weighted avg       0.85      0.83      0.84       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_qda = QuadraticDiscriminantAnalysis()\n",
    "clf_qda.fit(X_train, y_train)\n",
    "y_pred = clf_qda.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       698\n",
      "           1       0.54      0.33      0.41       102\n",
      "\n",
      "    accuracy                           0.88       800\n",
      "   macro avg       0.72      0.65      0.67       800\n",
      "weighted avg       0.86      0.88      0.87       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_lda = LinearDiscriminantAnalysis()\n",
    "clf_lda.fit(X_train, y_train)\n",
    "y_pred = clf_lda.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.3437502956648246\n",
      "Best parameter: {'max_features': 13, 'n_estimators': 1}\n"
     ]
    }
   ],
   "source": [
    "clf_forest = RandomForestClassifier(random_state=24)\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": np.arange(1,20),\n",
    "    \"max_features\": np.arange(1,20)\n",
    "}\n",
    "\n",
    "forest_reg_cv = GridSearchCV(clf_forest, params, cv = 5, scoring = \"f1\")\n",
    "forest_reg_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best score:\", forest_reg_cv.best_score_)\n",
    "print(\"Best parameter:\", forest_reg_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       698\n",
      "           1       0.31      0.26      0.29       102\n",
      "\n",
      "    accuracy                           0.83       800\n",
      "   macro avg       0.60      0.59      0.60       800\n",
      "weighted avg       0.82      0.83      0.83       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_forest = RandomForestClassifier(max_features = 13, n_estimators = 1, random_state=24)\n",
    "clf_forest.fit(X_train, y_train)\n",
    "y_pred = clf_forest.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.83      0.88       698\n",
      "           1       0.33      0.57      0.42       102\n",
      "\n",
      "    accuracy                           0.80       800\n",
      "   macro avg       0.63      0.70      0.65       800\n",
      "weighted avg       0.85      0.80      0.82       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_NB = GaussianNB()\n",
    "clf_NB.fit(X_train, y_train)\n",
    "y_pred = clf_NB.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:23:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best score: 0.40690365507637866\n",
      "Best parameter: {'scale_pos_weight': 52500.0}\n"
     ]
    }
   ],
   "source": [
    "clf_xg = XGBClassifier(random_state = 24)\n",
    "\n",
    "params = {\n",
    "    \"scale_pos_weight\": np.linspace(5000, 100000, 5),\n",
    "}\n",
    "\n",
    "clf_xg_cv = GridSearchCV(clf_xg, params, cv = 3, scoring = \"f1\")\n",
    "clf_xg_cv.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best score:\", clf_xg_cv.best_score_)\n",
    "print(\"Best parameter:\", clf_xg_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:23:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.86       698\n",
      "           1       0.28      0.53      0.37       102\n",
      "\n",
      "    accuracy                           0.77       800\n",
      "   macro avg       0.60      0.67      0.61       800\n",
      "weighted avg       0.84      0.77      0.80       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_xg = XGBClassifier(scale_pos_weight=52500, random_state=24)\n",
    "clf_xg.fit(X_train, y_train)\n",
    "y_pred = clf_xg.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    (\"xgb\", XGBClassifier(scale_pos_weight=52500,random_state=24)),\n",
    "    ('qda', QuadraticDiscriminantAnalysis()),\n",
    "    ('NB', GaussianNB()),\n",
    "    ('dt', DecisionTreeClassifier(max_depth=7, max_leaf_nodes=14,random_state=24))\n",
    "\n",
    "]\n",
    "clf_stacking = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:23:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93       698\n",
      "           1       0.51      0.25      0.33       102\n",
      "\n",
      "    accuracy                           0.87       800\n",
      "   macro avg       0.70      0.61      0.63       800\n",
      "weighted avg       0.85      0.87      0.85       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_stacking.fit(X_train, y_train)\n",
    "y_pred = clf_stacking.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('lda', LinearDiscriminantAnalysis()),\n",
    "    ('NB', GaussianNB()),\n",
    "    (\"xgb\", XGBClassifier(scale_pos_weight=52500,random_state=24))\n",
    "]\n",
    "clf_stacking = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:23:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94       698\n",
      "           1       0.67      0.32      0.44       102\n",
      "\n",
      "    accuracy                           0.89       800\n",
      "   macro avg       0.79      0.65      0.69       800\n",
      "weighted avg       0.88      0.89      0.88       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_stacking.fit(X_train, y_train)\n",
    "y_pred = clf_stacking.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
